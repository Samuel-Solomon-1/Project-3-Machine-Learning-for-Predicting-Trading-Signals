{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEUHKpFmAoNEvuUkPAr0wk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samuel-Solomon-1/Project-3-Machine-Learning-for-Predicting-Trading-Signals/blob/main/Project_3_Machine_Learning_for_Predicting_Trading_Signals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 3: Machine Learning for Predicting Trading Signals\n",
        "\n",
        "## Overview\n",
        "\n",
        "This project focuses on applying machine learning to predict 'Buy', 'Sell', or 'Hold' trading signals based on calculated technical indicators like **MACD** and **RSI**. We'll create these indicators manually using domain formulas, use them to generate labeled signals, and apply supervised machine learning models to classify trading decisions.\n",
        "\n",
        "By the end of this project, we aim to:\n",
        "\n",
        "- Engineer MACD and RSI from scratch\n",
        "- Generate trading signals: Buy, Sell, or Hold\n",
        "- Train and evaluate models: Logistic Regression, Random Forest, and SVM\n",
        "- Use accuracy, precision, and recall to assess model performance\n",
        "\n",
        "## Dataset\n",
        "\n",
        "The dataset used is the cleaned and transformed output from **Project 2**, which contains stock prices and technical features for selected tickers."
      ],
      "metadata": {
        "id": "QzSf9sG1_S0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Feature Engineering â€“ MACD, RSI & Signal Generation\n",
        "\n",
        "In this task, we will manually compute the technical indicators MACD and RSI using their mathematical formulas, without any third-party libraries. Based on the behavior of these indicators, we define:\n",
        "\n",
        "- **Buy**: If both MACD and RSI indicate a buy\n",
        "- **Sell**: If both indicate a sell\n",
        "- **Hold**: Otherwise"
      ],
      "metadata": {
        "id": "iBaYw-k-_c2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset (replace with your path)\n",
        "input_path = '/content/drive/MyDrive/Project2/train_clean.csv'\n",
        "df = pd.read_csv(input_path, parse_dates=['date'])\n",
        "\n",
        "# Sort by ticker and date to ensure correct calculation of rolling EMAs\n",
        "df = df.sort_values(['ticker', 'date'])\n",
        "\n",
        "# Function to calculate EMA\n",
        "def ema(series, span):\n",
        "    return series.ewm(span=span, adjust=False).mean()\n",
        "\n",
        "# Compute MACD and Signal Line for each ticker group\n",
        "def compute_macd(group):\n",
        "    close = group['close_scaled']\n",
        "    ema12 = ema(close, 12)\n",
        "    ema26 = ema(close, 26)\n",
        "    macd_line = ema12 - ema26\n",
        "    signal_line = ema(macd_line, 9)\n",
        "    macd_diff = macd_line - signal_line\n",
        "\n",
        "    group = group.assign(macd=macd_line, macd_signal=signal_line, macd_diff=macd_diff)\n",
        "    return group\n",
        "\n",
        "df = df.groupby('ticker').apply(compute_macd).reset_index(drop=True)\n",
        "\n",
        "# Compute RSI manually for each ticker group\n",
        "def compute_rsi(group, period=14):\n",
        "    delta = group['close_scaled'].diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "\n",
        "    avg_gain = gain.ewm(com=period - 1, min_periods=period).mean()\n",
        "    avg_loss = loss.ewm(com=period - 1, min_periods=period).mean()\n",
        "\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    group = group.assign(rsi=rsi)\n",
        "    return group\n",
        "\n",
        "df = df.groupby('ticker').apply(compute_rsi).reset_index(drop=True)\n",
        "\n",
        "# Define signal generation functions\n",
        "\n",
        "def get_macd_signal(row):\n",
        "    # Buy when MACD crosses above signal line (macd_diff > 0)\n",
        "    if row['macd_diff'] > 0:\n",
        "        return 'Buy'\n",
        "    # Sell when MACD crosses below signal line (macd_diff < 0)\n",
        "    elif row['macd_diff'] < 0:\n",
        "        return 'Sell'\n",
        "    else:\n",
        "        return 'Hold'\n",
        "\n",
        "def get_rsi_signal(row):\n",
        "    if row['rsi'] < 30:\n",
        "        return 'Buy'\n",
        "    elif row['rsi'] > 70:\n",
        "        return 'Sell'\n",
        "    else:\n",
        "        return 'Hold'\n",
        "\n",
        "def combine_signals(row):\n",
        "    macd_signal = get_macd_signal(row)\n",
        "    rsi_signal = get_rsi_signal(row)\n",
        "    if macd_signal == 'Buy' and rsi_signal == 'Buy':\n",
        "        return 'Buy'\n",
        "    elif macd_signal == 'Sell' and rsi_signal == 'Sell':\n",
        "        return 'Sell'\n",
        "    else:\n",
        "        return 'Hold'\n",
        "\n",
        "# Apply signal generation\n",
        "df['macd_signal_flag'] = df.apply(get_macd_signal, axis=1)\n",
        "df['rsi_signal_flag'] = df.apply(get_rsi_signal, axis=1)\n",
        "df['signal'] = df.apply(combine_signals, axis=1)\n",
        "\n",
        "# Preview results\n",
        "print(df[['ticker', 'date', 'close_scaled', 'macd', 'macd_signal', 'macd_diff', 'rsi', 'macd_signal_flag', 'rsi_signal_flag', 'signal']].head(20))\n",
        "\n",
        "# Save to csv for further tasks\n",
        "output_path = '/content/drive/MyDrive/Project3/train_with_signals.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"Saved processed data with signals to {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8G6xBON_hxp",
        "outputId": "28ca3033-8017-4032-9d07-1905585016a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1700276475.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('ticker').apply(compute_macd).reset_index(drop=True)\n",
            "/tmp/ipython-input-13-1700276475.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('ticker').apply(compute_rsi).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ticker       date  close_scaled      macd   macd_signal  macd_diff  \\\n",
            "0    AAPL 1981-01-26     -0.397000  0.000000  0.000000e+00   0.000000   \n",
            "1    AAPL 1981-01-27     -0.397042 -0.000003 -6.608318e-07  -0.000003   \n",
            "2    AAPL 1981-01-28     -0.397207 -0.000019 -4.343057e-06  -0.000015   \n",
            "3    AAPL 1981-01-29     -0.397394 -0.000046 -1.268986e-05  -0.000033   \n",
            "4    AAPL 1981-01-30     -0.397663 -0.000088 -2.778927e-05  -0.000060   \n",
            "5    AAPL 1981-02-02     -0.397932 -0.000142 -5.056164e-05  -0.000091   \n",
            "6    AAPL 1981-02-03     -0.397767 -0.000169 -7.419093e-05  -0.000095   \n",
            "7    AAPL 1981-02-04     -0.397601 -0.000175 -9.430619e-05  -0.000080   \n",
            "8    AAPL 1981-02-05     -0.397601 -0.000178 -1.109495e-04  -0.000067   \n",
            "9    AAPL 1981-02-06     -0.397580 -0.000176 -1.239609e-04  -0.000052   \n",
            "10   AAPL 1981-02-09     -0.397829 -0.000193 -1.376963e-04  -0.000055   \n",
            "11   AAPL 1981-02-10     -0.397829 -0.000203 -1.508516e-04  -0.000053   \n",
            "12   AAPL 1981-02-11     -0.397974 -0.000221 -1.649228e-04  -0.000056   \n",
            "13   AAPL 1981-02-12     -0.398015 -0.000236 -1.791154e-04  -0.000057   \n",
            "14   AAPL 1981-02-13     -0.398119 -0.000253 -1.938839e-04  -0.000059   \n",
            "15   AAPL 1981-02-17     -0.398015 -0.000255 -2.061452e-04  -0.000049   \n",
            "16   AAPL 1981-02-18     -0.397829 -0.000239 -2.127486e-04  -0.000026   \n",
            "17   AAPL 1981-02-19     -0.398098 -0.000245 -2.192702e-04  -0.000026   \n",
            "18   AAPL 1981-02-20     -0.398326 -0.000266 -2.285335e-04  -0.000037   \n",
            "19   AAPL 1981-02-23     -0.398264 -0.000273 -2.375174e-04  -0.000036   \n",
            "\n",
            "          rsi macd_signal_flag rsi_signal_flag signal  \n",
            "0         NaN             Hold            Hold   Hold  \n",
            "1         NaN             Sell            Hold   Hold  \n",
            "2         NaN             Sell            Hold   Hold  \n",
            "3         NaN             Sell            Hold   Hold  \n",
            "4         NaN             Sell            Hold   Hold  \n",
            "5         NaN             Sell            Hold   Hold  \n",
            "6         NaN             Sell            Hold   Hold  \n",
            "7         NaN             Sell            Hold   Hold  \n",
            "8         NaN             Sell            Hold   Hold  \n",
            "9         NaN             Sell            Hold   Hold  \n",
            "10        NaN             Sell            Hold   Hold  \n",
            "11        NaN             Sell            Hold   Hold  \n",
            "12        NaN             Sell            Hold   Hold  \n",
            "13        NaN             Sell            Hold   Hold  \n",
            "14  18.775890             Sell             Buy   Hold  \n",
            "15  26.319802             Sell             Buy   Hold  \n",
            "16  37.561245             Sell            Hold   Hold  \n",
            "17  30.356635             Sell            Hold   Hold  \n",
            "18  25.840152             Sell             Buy   Hold  \n",
            "19  28.945097             Sell             Buy   Hold  \n",
            "Saved processed data with signals to /content/drive/MyDrive/Project3/train_with_signals.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Data Preparation and Splitting\n",
        "\n",
        "In this task, we prepare the dataset for machine learning by integrating the computed technical indicators and trading signals into the main dataset. The `Signal` column (with values \"Buy\", \"Sell\", or \"Hold\") will serve as our target label for supervised learning.\n",
        "\n",
        "Steps include:\n",
        "\n",
        "1. Loading the cleaned datasets containing technical indicators and signals.\n",
        "2. Encoding the categorical target labels (`Signal`) into numeric form suitable for modeling.\n",
        "3. Selecting relevant feature columns for the prediction task.\n",
        "4. Splitting the combined dataset into training, validation, and testing sets (if not already split).\n",
        "5. Saving the prepared datasets for use in the modeling phase.\n",
        "\n",
        "This preparation ensures the data is structured correctly, with features and labels ready for machine learning algorithms."
      ],
      "metadata": {
        "id": "FMaovERiCe8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the processed dataset with signals\n",
        "input_path = '/content/drive/MyDrive/Project3/train_with_signals.csv'\n",
        "df = pd.read_csv(input_path, parse_dates=['date'])\n",
        "\n",
        "# Drop rows with missing RSI if any (optional)\n",
        "df = df.dropna(subset=['rsi']).reset_index(drop=True)\n",
        "\n",
        "# Encode target signal labels (Buy, Hold, Sell) to integers\n",
        "label_encoder = LabelEncoder()\n",
        "df['signal_encoded'] = label_encoder.fit_transform(df['signal'])\n",
        "\n",
        "# Select features to use for modeling\n",
        "feature_cols = ['macd', 'macd_signal', 'rsi']\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df['signal_encoded']\n",
        "\n",
        "# Split data: 70% train, 15% validation, 15% test (stratified by target)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Optional: Combine X and y to save prepared splits\n",
        "train_df = X_train.copy()\n",
        "train_df['signal_encoded'] = y_train\n",
        "\n",
        "val_df = X_val.copy()\n",
        "val_df['signal_encoded'] = y_val\n",
        "\n",
        "test_df = X_test.copy()\n",
        "test_df['signal_encoded'] = y_test\n",
        "\n",
        "# Save the prepared datasets to Google Drive\n",
        "output_dir = '/content/drive/MyDrive/Project3'\n",
        "train_df.to_csv(f'{output_dir}/train_prepared.csv', index=False)\n",
        "val_df.to_csv(f'{output_dir}/val_prepared.csv', index=False)\n",
        "test_df.to_csv(f'{output_dir}/test_prepared.csv', index=False)\n",
        "\n",
        "print(f\"Data split and saved successfully!\")\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")\n",
        "print(f\"Encoded classes: {list(label_encoder.classes_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw5l-lzgCgP5",
        "outputId": "cc74cbcd-2755-4f0e-f03d-6688260797f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split and saved successfully!\n",
            "Training set size: 81109\n",
            "Validation set size: 17381\n",
            "Test set size: 17381\n",
            "Encoded classes: ['Buy', 'Hold', 'Sell']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Model Building and Validation\n",
        "\n",
        "In this task, we implement and train three supervised machine learning models to predict stock trading signals (`Buy`, `Sell`, `Hold`) based on the technical indicators computed previously.\n",
        "\n",
        "The models used are:\n",
        "1. **Logistic Regression**\n",
        "2. **Random Forest Classifier**\n",
        "3. **Support Vector Machine (SVM)**\n",
        "\n",
        "### Process\n",
        "\n",
        "- Load the prepared training, validation, and test datasets.\n",
        "- Select key technical indicator features (`macd`, `macd_signal`, `rsi`) as inputs.\n",
        "- Encode the categorical target variable `signal` into numerical labels.\n",
        "- Train each model on the training set.\n",
        "- Validate each modelâ€™s performance on the validation set using classification metrics such as accuracy, precision, recall, and F1-score.\n",
        "- Compare results to identify the best-performing model.\n",
        "\n",
        "### Notes\n",
        "\n",
        "- Logistic Regression provides a simple baseline model.\n",
        "- Random Forest can capture complex nonlinear relationships.\n",
        "- SVMs are powerful classifiers but can be computationally intensive on large datasets.\n",
        "\n",
        "This step establishes a foundation for predictive modeling and informs the choice of models for further optimization and testing."
      ],
      "metadata": {
        "id": "YPhb87POFZHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/Project3'\n",
        "\n",
        "train_df = pd.read_csv(f'{input_dir}/train_prepared.csv')\n",
        "val_df = pd.read_csv(f'{input_dir}/val_prepared.csv')\n",
        "test_df = pd.read_csv(f'{input_dir}/test_prepared.csv')\n",
        "\n",
        "# Feature columns based on your data\n",
        "feature_cols = ['macd', 'macd_signal', 'rsi']\n",
        "\n",
        "X_train, y_train = train_df[feature_cols], train_df['signal_encoded']\n",
        "X_val, y_val = val_df[feature_cols], val_df['signal_encoded']\n",
        "X_test, y_test = test_df[feature_cols], test_df['signal_encoded']\n",
        "\n",
        "# Shuffle training data\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"SVM\": SVC(kernel='rbf', probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Validation performance for {name}:\")\n",
        "    y_pred = model.predict(X_val)\n",
        "    print(classification_report(y_val, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "best_model_name = \"Random Forest\"  # Choose the best based on above\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "print(f\"\\nEvaluating best model ({best_model_name}) on test set...\")\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"Test Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1P2BLHBFbP8",
        "outputId": "668899f0-a7bd-4ac6-8f8e-d8e3408ac831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "Validation performance for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.99      1.00      1.00     17294\n",
            "           2       0.00      0.00      0.00        47\n",
            "\n",
            "    accuracy                           0.99     17381\n",
            "   macro avg       0.33      0.33      0.33     17381\n",
            "weighted avg       0.99      0.99      0.99     17381\n",
            "\n",
            "Confusion Matrix:\n",
            "[[    0    40     0]\n",
            " [    0 17294     0]\n",
            " [    0    47     0]]\n",
            "\n",
            "Training Random Forest...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation performance for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.35      0.48        40\n",
            "           1       1.00      1.00      1.00     17294\n",
            "           2       1.00      0.19      0.32        47\n",
            "\n",
            "    accuracy                           1.00     17381\n",
            "   macro avg       0.92      0.51      0.60     17381\n",
            "weighted avg       1.00      1.00      1.00     17381\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   14    26     0]\n",
            " [    4 17290     0]\n",
            " [    0    38     9]]\n",
            "\n",
            "Training SVM...\n",
            "Validation performance for SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.99      1.00      1.00     17294\n",
            "           2       0.00      0.00      0.00        47\n",
            "\n",
            "    accuracy                           0.99     17381\n",
            "   macro avg       0.33      0.33      0.33     17381\n",
            "weighted avg       0.99      0.99      0.99     17381\n",
            "\n",
            "Confusion Matrix:\n",
            "[[    0    40     0]\n",
            " [    0 17294     0]\n",
            " [    0    47     0]]\n",
            "\n",
            "Evaluating best model (Random Forest) on test set...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.30      0.43        40\n",
            "           1       1.00      1.00      1.00     17295\n",
            "           2       0.75      0.13      0.22        46\n",
            "\n",
            "    accuracy                           1.00     17381\n",
            "   macro avg       0.83      0.48      0.55     17381\n",
            "weighted avg       0.99      1.00      0.99     17381\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[   12    28     0]\n",
            " [    4 17289     2]\n",
            " [    0    40     6]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Model Evaluation and Optimization\n",
        "\n",
        "## Description\n",
        "\n",
        "In this task, we perform a thorough evaluation of the trained models on the test dataset to measure their real-world predictive performance. Beyond just evaluating, we will optimize model performance by tuning hyperparameters using techniques such as Grid Search with cross-validation. This helps ensure that the models generalize well and are robust to unseen data.\n",
        "\n",
        "**Key points:**\n",
        "\n",
        "- Evaluate models (Logistic Regression, Random Forest, SVM) on the test set using metrics like accuracy, precision, recall, F1-score, and confusion matrix.\n",
        "- Use cross-validation (e.g., Stratified K-Fold) on the training data for hyperparameter tuning.\n",
        "- Perform hyperparameter search using Grid Search or Randomized Search.\n",
        "- Re-train models with optimized hyperparameters and compare results.\n",
        "- Document findings and select the best performing model."
      ],
      "metadata": {
        "id": "moHCAhIOLa88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Define models with initial parameters and parameter grids for tuning\n",
        "models_params = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"model\": LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
        "        \"params\": {\n",
        "            \"C\": [0.01, 0.1, 1, 10],\n",
        "            \"solver\": [\"liblinear\", \"lbfgs\"]\n",
        "        }\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [None, 10, 20],\n",
        "            \"min_samples_split\": [2, 5],\n",
        "            \"min_samples_leaf\": [1, 2]\n",
        "        }\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"model\": SVC(class_weight='balanced', probability=True, random_state=42),\n",
        "        \"params\": {\n",
        "            \"C\": [0.1, 1, 10],\n",
        "            \"kernel\": [\"rbf\", \"linear\"],\n",
        "            \"gamma\": [\"scale\", \"auto\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Stratified K-Fold cross-validation setup\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for model_name, mp in models_params.items():\n",
        "    print(f\"\\nStarting Grid Search for {model_name}...\")\n",
        "    grid_search = GridSearchCV(mp['model'], mp['params'], cv=cv, scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best params for {model_name}: {grid_search.best_params_}\")\n",
        "    best_models[model_name] = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate best models on the test set\n",
        "for model_name, model in best_models.items():\n",
        "    print(f\"\\nEvaluating {model_name} on test data:\")\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wPa6KlKbLbVF",
        "outputId": "ff60d655-6d11-403b-d486-e2536c1e9c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Grid Search for Logistic Regression...\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Best params for Logistic Regression: {'C': 0.01, 'solver': 'liblinear'}\n",
            "\n",
            "Starting Grid Search for Random Forest...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "Best params for Random Forest: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "\n",
            "Starting Grid Search for SVM...\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights Gathered and Conclusion\n",
        "\n",
        "#### Overview\n",
        "\n",
        "This task summarizes the key findings and insights gathered during the end-to-end process of generating trading signals using machine learning techniques. From manually computing MACD and RSI to optimizing model parameters, the project aimed to evaluate how well simple technical indicators can drive predictive models in a financial context.\n",
        "\n",
        "#### Key Insights\n",
        "\n",
        "1. **Manual Feature Engineering with Technical Indicators**\n",
        "   - Computing MACD and RSI from scratch offered transparency and customization.\n",
        "   - It ensured we fully understood the inner workings of these indicators, reinforcing their limitations and assumptions.\n",
        "\n",
        "2. **Class Imbalance Dominated by â€˜Holdâ€™ Signals**\n",
        "   - Most entries in the dataset were labeled as `Hold`, resulting in highly imbalanced data.\n",
        "   - This made it difficult for models to detect and predict minority classes like `Buy` and `Sell`.\n",
        "\n",
        "3. **Model Performance Comparison**\n",
        "   - **Random Forest** showed the best performance among the three models:\n",
        "     - It handled non-linear patterns well and generalized better across classes.\n",
        "     - After hyperparameter tuning, it showed improved recall on minority classes.\n",
        "   - **Logistic Regression** and **SVM** performed poorly on the minority classes even after tuning, primarily predicting `Hold`.\n",
        "\n",
        "4. **Effectiveness of Grid Search and Cross-Validation**\n",
        "   - Grid Search CV helped fine-tune hyperparameters for each model.\n",
        "   - Stratified 5-fold cross-validation ensured a fair evaluation by preserving class proportions across folds.\n",
        "\n",
        "5. **Limitations of MACD and RSI for Signal Prediction**\n",
        "   - These indicators are **lagging** and may not capture sharp price movements or market news.\n",
        "   - This limits their usefulness in high-frequency or volatile trading scenarios.\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "This project demonstrated that technical indicators like MACD and RSI can be used to build machine learning models for generating trading signals. However, their predictive power is limited, especially under class imbalance and market noise.\n",
        "\n",
        "To improve results:\n",
        "- Introduce additional features (e.g., Bollinger Bands, volume trends, sentiment scores).\n",
        "- Apply class balancing techniques such as **SMOTE** or **undersampling**.\n",
        "- Explore more sophisticated models (e.g., Gradient Boosting, LSTM for sequence modeling).\n",
        "- Incorporate profitability-focused metrics beyond accuracy and recall.\n",
        "\n",
        "While machine learning can support trading decisions, it must be paired with domain expertise and strong risk management to be effective in real-world applications."
      ],
      "metadata": {
        "id": "W0CT9eD3Z8MP"
      }
    }
  ]
}